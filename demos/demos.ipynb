{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from ca_funcs import make_glider, make_game_of_life\n",
    "from utils import *\n",
    "from train_ca import *\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up some global variables\n",
    "USE_GPU = True\n",
    "\n",
    "if USE_GPU:\n",
    "    # device on dedicated node\n",
    "    #device = '/device:GPU:0'\n",
    "    # device assigned via slurm\n",
    "    device = '/job:localhost/replica:0/task:0/device:XLA_GPU:0'\n",
    "else:\n",
    "    device = '/cpu:0'\n",
    "\n",
    "# Constant to control how often we print when training models\n",
    "print_every = 100\n",
    "\n",
    "print('Using device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## MULTI-GPUs Config ##############\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "#config.log_device_placement = True\n",
    "config.log_device_placement = False\n",
    "#config.gpu_options.visible_device_list='0,1,2,3'\n",
    "config.gpu_options.visible_device_list='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed in tensorflow at graph level\n",
    "tf.compat.v1.set_random_seed(111)\n",
    "\n",
    "# Set the session in tensorflow\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "\n",
    "# Set the session in keras\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "print('Number of devices: {}\\n'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Make training data\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "## Make training data\n",
    "train_size, wspan, hspan = (100, 10, 10)\n",
    "X_train = tf.convert_to_tensor(np.random.choice([0,1], (train_size, wspan, hspan), p=[.5,.5]), tf.float32)\n",
    "gol = make_game_of_life()\n",
    "Y_train = gol(tf.convert_to_tensor(X_train, tf.float32))\n",
    "\n",
    "X_train = X_train[..., tf.newaxis]\n",
    "Y_train = Y_train[..., tf.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Define and build model\n",
    "tf.random.set_seed(0)\n",
    "layer_dims = [10, 10, 10]\n",
    "num_classes = 2\n",
    "\n",
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "loss = lambda x, y : tf.keras.losses.categorical_crossentropy(tf.reshape(x, shape=(-1, num_classes)), \n",
    "                                                              tf.reshape(y, shape=(-1, num_classes)), \n",
    "                                                              from_logits=True)\n",
    "model = initialize_model((wspan, hspan), layer_dims, num_classes=num_classes)\n",
    "# model = initialize_model((wspan, hspan), [10, 10, 10, 10], num_classes=num_classes, totalistic=True, bc=\"periodic\")\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-2), loss=loss)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Run training\n",
    "Y_train_onehot = tf.squeeze(tf.one_hot(tf.cast(Y_train, tf.int32), num_classes))\n",
    "train_history = model.fit(x=X_train, y=Y_train_onehot, epochs=100, batch_size=10, verbose=0)\n",
    "\n",
    "plt.plot(train_history.history['loss'], 'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot results\n",
    "\n",
    "## Generate testing data\n",
    "X_test = tf.convert_to_tensor(np.moveaxis(np.dstack([make_glider(10), make_glider(10)]), 2, 0), tf.float32)\n",
    "# X_test = tf.convert_to_tensor(make_glider(10), tf.float32)[tf.newaxis, ...]\n",
    "Y_test = gol(X_test)\n",
    "X_test = X_test[..., tf.newaxis]\n",
    "Y_test = Y_test[..., tf.newaxis]\n",
    "\n",
    "Y_pred = logit_to_pred(model(X_test), shape=(-1, wspan, hspan))\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(tf.squeeze(X_test[0]))\n",
    "plt.axis('off')\n",
    "plt.title(\"Input\")\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(tf.squeeze(Y_test[0]))\n",
    "plt.axis('off')\n",
    "plt.title(\"Expected Output\")\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(tf.squeeze(Y_pred[0]))\n",
    "plt.axis('off')\n",
    "plt.title(\"Observed Output\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save and load a model\n",
    "model.save('path_to_my_model.h5')\n",
    "del model\n",
    "#model = tf.keras.models.load_model('path_to_my_model.h5', custom_objects={'Wraparound2D': Wraparound2D})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show activation patterns of hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "inp = model.input                                           # input placeholder\n",
    "outputs = [layer.output for layer in model.layers]          # all layer outputs\n",
    "functor = K.function(inp, outputs)   # evaluation function\n",
    "\n",
    "layer_outs = functor([X_test, 1.])\n",
    "\n",
    "\n",
    "\n",
    "# Plot activations of different neurons in different layers \n",
    "all_layer_activations = list()\n",
    "\n",
    "min_max_scaler = lambda x : (x - np.min(x))/(np.max(x) - np.min(x))\n",
    "# min_max_scaler = lambda x : (x - np.mean(x))\n",
    "for j in range(1, 5):\n",
    "    if j==1:\n",
    "        layer_im = np.hstack([min_max_scaler(layer_outs[1][0][..., i]) for i in range(10)])\n",
    "    else:\n",
    "        pattern = np.reshape(layer_outs[j][0], (wspan, hspan, -1))\n",
    "        layer_im = np.hstack([min_max_scaler(pattern[..., i]) for i in range(10)])\n",
    "    all_layer_activations.append(layer_im)\n",
    "\n",
    "        \n",
    "plt.figure()\n",
    "plt.imshow(np.vstack(all_layer_activations))\n",
    "plt.title(\"Activations of hidden layers given \\\"Glider\\\" input\")\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(np.squeeze(np.dstack(model.layers[1].weights[0].numpy())))\n",
    "plt.title(\"Convolutional filters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
